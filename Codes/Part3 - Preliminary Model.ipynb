{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5716,"status":"ok","timestamp":1647775908319,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"ZXBHSHB3gVt0","outputId":"77791722-afad-43ab-85fb-14abe7c517ef"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/var/folders/kd/l9dy75fj7517_j0sd37zvf1w0000gn/T/ipykernel_20332/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21457,"status":"ok","timestamp":1647775929766,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"sk0r4REWgXAl","outputId":"46e2d999-9743-4f3a-a023-882991d0131e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","openjdk-8-jre is already the newest version (8u312-b07-0ubuntu1~18.04).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","scala is already the newest version (2.11.12-4~18.04).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","Requirement already satisfied: py4j in /usr/local/lib/python3.7/dist-packages (0.10.9.5)\n"]}],"source":["!apt-get install openjdk-8-jre\n","!apt-get install scala\n","!pip install py4j\n","!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n","!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n","!pip install -q findspark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1647775929767,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"Z_vqacTngYKD","outputId":"703dde2c-7bb3-4926-d1e8-2342a6115c79"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove '*.zip': No such file or directory\n","rm: cannot remove 'sample_data': No such file or directory\n","drive  spark-3.1.2-bin-hadoop3.2\n"]}],"source":["!rm -r *.tgz *.zip sample_data\n","!ls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1647775929768,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"OICbHYVWgZLx"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647775929768,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"7uc4V2NdgjVV"},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/My Drive/CS5344/GP')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3893,"status":"ok","timestamp":1647775933654,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"OyW7WTWER2UP","outputId":"55013baf-d4e2-470f-8356-9a2ade012f1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","time: 157 Âµs (started: 2022-03-20 11:32:12 +00:00)\n"]}],"source":["# output operating time\n","!pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6903,"status":"ok","timestamp":1647775940553,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"p9odbydvUVdR","outputId":"8416b6fb-c02d-4b55-eb4c-194d8c1f4654"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/yishun/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /Users/yishun/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/yishun/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /Users/yishun/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","env: bash: No such file or directory\n"]},{"ename":"RuntimeError","evalue":"Java gateway process exited before sending its port number","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/var/folders/kd/l9dy75fj7517_j0sd37zvf1w0000gn/T/ipykernel_20332/2598214840.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TestSetup\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda/anaconda3/lib/python3.9/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda/anaconda3/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda/anaconda3/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n","\u001b[0;32m~/anaconda/anaconda3/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda/anaconda3/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","import math\n","import findspark\n","findspark.init()\n","from pyspark import SparkConf, SparkContext\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import CountVectorizer, CountVectorizerModel, HashingTF, IDF, IDFModel\n","\n","# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","spark = SparkSession.builder.appName(\"TestSetup\").getOrCreate()\n","sc = spark.sparkContext"]},{"cell_type":"markdown","metadata":{"id":"gxWsznskdYxl"},"source":["## Input 2 labeled datasets and combine them together\n","### Output: \n","- label_data (dataframe, column=['id', 'label', 'text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2043,"status":"ok","timestamp":1647775942593,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"0y2BjOofWEkV","outputId":"3c472296-1271-4891-9767-aa32ef773d27"},"outputs":[{"name":"stdout","output_type":"stream","text":["# of records of the first text datasets: 44898\n","time: 2.32 s (started: 2022-03-20 11:32:19 +00:00)\n"]}],"source":["# input the first labeled dataset\n","origin_Fake = pd.read_csv('/Users/yishun/Desktop/BAModule/CS5344/group project/Fake.csv')\n","origin_True = pd.read_csv('/Users/yishun/Desktop/BAModule/CS5344/group project/True.csv')\n","# print(origin_Fake.head())\n","# print(origin_True.head())\n","\n","# keep the text features and generate the labels\n","origin_Fake['text'] = origin_Fake.apply(lambda row: row['title']+\" \"+row['text'], axis=1)\n","origin_True['text'] = origin_Fake.apply(lambda row: row[0]+row[1], axis=1)\n","origin_Fake['label'] = 0 # Fake\n","origin_True['label'] = 1 # True\n","label_data1 = pd.DataFrame(columns=['text', 'label'])\n","label_data1 = label_data1.append(origin_Fake[['text','label']])\n","label_data1 = label_data1.append(origin_True[['text','label']])\n","\n","# remove null data\n","label_data1 = label_data1.dropna()\n","# print(label_data1.head())\n","print(\"# of records of the first text datasets:\", len(label_data1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2095,"status":"ok","timestamp":1647775944685,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"gVvihAbwWtVg","outputId":"9a0717fb-30e8-4a5e-8bb9-ff956154fd06"},"outputs":[{"name":"stdout","output_type":"stream","text":["# of records of the second text datasets: 40000\n","time: 2.16 s (started: 2022-03-20 11:32:21 +00:00)\n"]}],"source":["# input the second labeled dataset\n","origin_train = pd.read_csv('/Users/yishun/Desktop/BAModule/CS5344/group project/train.csv')\n","# origin_test = pd.read_csv('/content/drive/My Drive/CS5344/GP/test.csv') # No label\n","# origin_train = origin_train.append(origin_test)\n","# print(origin_train)\n","\n","# keep the text features and remove null data\n","origin_train = origin_train[['title','text','class']]\n","origin_train = origin_train.dropna()\n","origin_train['text'] = origin_train.apply(lambda row: row['title']+\" \"+row['text'], axis=1)\n","origin_train = origin_train.replace({'Fake':0, 'Real':1})\n","origin_train = origin_train.rename(columns={'class':'label'})\n","label_data2 = origin_train[['text','label']]\n","# print(label_data2.head())\n","print(\"# of records of the second text datasets:\", len(label_data2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647775944685,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"i_uzJs8aqFBh","outputId":"9e64f4e5-e889-4e8f-a9e6-14825dcba83b"},"outputs":[{"name":"stdout","output_type":"stream","text":["   id                                               text label\n","0   0   Donald Trump Sends Out Embarrassing New Yearâ...     0\n","1   1   Drunk Bragging Trump Staffer Started Russian ...     0\n","2   2   Sheriff David Clarke Becomes An Internet Joke...     0\n","3   3   Trump Is So Obsessed He Even Has Obamaâs Name...     0\n","4   4   Pope Francis Just Called Out Donald Trump Dur...     0\n","# of records of the labeled text dataset: 84898\n","time: 47.3 ms (started: 2022-03-20 11:32:23 +00:00)\n"]}],"source":["# combine the labeled datasets together\n","label_data = label_data1.append(label_data2)\n","label_data['id'] = list(range(len(label_data))) \n","label_data = label_data[['id','text','label']]\n","print(label_data.head())\n","print(\"# of records of the labeled text dataset:\", len(label_data))"]},{"cell_type":"markdown","metadata":{"id":"_orF77DjeRkl"},"source":["## Input the unlabeled dataset\n","### Output: \n","- main_data (dataframe, column=['id', 'text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1057,"status":"ok","timestamp":1647775945740,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"6d0_zvs0YdpF","outputId":"69dd33b6-3e8b-40e4-c3c3-e87464da357b"},"outputs":[{"name":"stdout","output_type":"stream","text":["<bound method NDFrame.head of                                              id  \\\n","0      6a175f46bcd24d39b3e962ad0f29936721db70db   \n","1      2bdc29d12605ef9cf3f09f9875040a7113be5d5b   \n","2      c70e149fdd53de5e61c29281100b9de0ed268bc3   \n","3      7cf7c15731ac2a116dd7f629bd57ea468ed70284   \n","4      0206b54719c7e241ffe0ad4315b808290dbe6c0f   \n","...                                         ...   \n","12908  613e1a6e130b5a3f5df62c8fb0b73667742a43db   \n","12909  dedc36a34e5cb1062bf4627d314227f60cd9a708   \n","12910  cd8bb1ae426287f3a63c2979b3b5dfb0277b10e2   \n","12911  213eb9eeb5479ad2588b54b24acd53bc8ead8e8c   \n","12912  795f05dce10c27ff4e7b3f39ddf4e75075f5421c   \n","\n","                                                    text  \n","0      Muslims BUSTED: They Stole Millions In Govât B...  \n","1      Re: Why Did Attorney General Loretta Lynch Ple...  \n","2      BREAKING: Weiner Cooperating With FBI On Hilla...  \n","3      PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...  \n","4      FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...  \n","...                                                  ...  \n","12908  Tesla Earnings Smash Expectations After Dramat...  \n","12909  Rules For Rulers (Or How The World Really Work...  \n","12910  Fact Check: Trump Is Right that Clinton Might ...  \n","12911  Caught On Tape: ISIS Destroys Iraqi Abrams Wit...  \n","12912  ObamaCare Architect Admits \"The Law Is Working...  \n","\n","[11677 rows x 2 columns]>\n","# of records of the main text dataset: 11677\n","time: 1.06 s (started: 2022-03-20 11:32:23 +00:00)\n"]}],"source":["# input the unlabeled dataset\n","origin_main = pd.read_csv('/Users/yishun/Desktop/BAModule/CS5344/group project/fake_news_dataset.csv')\n","# print(origin_main.head())\n","\n","# exclude other language\n","origin_main = origin_main[origin_main['language']=='english'] \n","\n","\n","# keep the text features and remove null data\n","origin_main = origin_main[['uuid','title','text']]\n","origin_main = origin_main.rename(columns={'uuid':'id'})\n","origin_main = origin_main.dropna()\n","origin_main['text'] = origin_main.apply(lambda row: row['title']+\" \"+row['text'], axis=1)\n","main_data = origin_main[['id','text']]\n","# print(main_data['id'].unique()) # the id is unique\n","print(main_data.head)\n","print(\"# of records of the main text dataset:\", len(main_data))"]},{"cell_type":"markdown","metadata":{"id":"OcHSGt4eebGY"},"source":["## Data Preprocessing\n","### Steps:\n","- convert to lowercase\n","- remove numbers\n","- remove puctuations\n","- remove stopwords\n","- lemmatization\n","\n","### Output: \n","- label_data_df (spark dataframe, column=['id', 'label', 'token'])\n","- main_data_df (spark dataframe, column=['id', 'token'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2107,"status":"ok","timestamp":1647775947842,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"kEJjOXzjtVb4","outputId":"a7ce98d3-7779-4bcd-b1d2-4490818feef8"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 2.15 s (started: 2022-03-20 11:32:24 +00:00)\n"]}],"source":["# load the data into rdd format\n","label_data_rdd = sc.parallelize(label_data.values.tolist())\n","main_data_rdd = sc.parallelize(main_data.values.tolist())\n","\n","# transformed to lowercase\n","label_data_lower = label_data_rdd.map(lambda f: ((f[0], f[2]), str.lower(f[1])))\n","main_data_lower = main_data_rdd.map(lambda f: (f[0], str.lower(f[1])))\n","# print(label_data_lower.take(5))\n","\n","# remove numbers\n","label_data_no_number = label_data_lower.map(lambda f: (f[0], re.sub(r'\\d+', '', f[1])))\n","main_data_no_number = main_data_lower.map(lambda f: (f[0], re.sub(r'\\d+', '', f[1])))\n","# print(label_data_no_number.take(5))\n","\n","# remove punctuation and split it into words\n","label_data_words = label_data_no_number.map(lambda f: (f[0], re.split(r'[^\\w]+',f[1])))\n","label_data_words = label_data_words.map(lambda f: (f[0], [i for i in f[1] if i != '']))\n","main_data_words = main_data_no_number.map(lambda f: (f[0], re.split(r'[^\\w]+',f[1])))\n","main_data_words = main_data_words.map(lambda f: (f[0], [i for i in f[1] if i != '']))\n","# print(label_data_words.take(5))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2485,"status":"ok","timestamp":1647775950324,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"fW-5Hyvs0c9B","outputId":"71086ab9-4d94-49b9-9665-e77db6db022c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[((0, 0), ['donald', 'trump', 'sends', 'embarrassing', 'new', 'year', 'eve', 'message', 'disturbing', 'donald', 'trump', 'wish', 'americans', 'happy', 'new', 'year', 'leave', 'instead', 'give', 'shout', 'enemies', 'haters', 'dishonest', 'fake', 'news', 'media', 'former', 'reality', 'show', 'star', 'one', 'job', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', 'president', 'angry', 'pants', 'tweeted', 'great', 'year', 'america', 'country', 'rapidly', 'grows', 'stronger', 'smarter', 'want', 'wish', 'friends', 'supporters', 'enemies', 'haters', 'even', 'dishonest', 'fake', 'news', 'media', 'happy', 'healthy', 'new', 'year', 'great', 'year', 'america', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'trump', 'tweet', 'went', 'welll', 'expect', 'kind', 'president', 'sends', 'new', 'year', 'greeting', 'like', 'despicable', 'petty', 'infantile', 'gibberish', 'trump', 'lack', 'decency', 'even', 'allow', 'rise', 'gutter', 'long', 'enough', 'wish', 'american', 'citizens', 'happy', 'new', 'year', 'bishop', 'talbert', 'swan', 'talbertswan', 'december', 'one', 'likes', 'calvin', 'calvinstowell', 'december', 'impeachment', 'would', 'make', 'great', 'year', 'america', 'also', 'accept', 'regaining', 'control', 'congress', 'miranda', 'yaver', 'mirandayaver', 'december', 'hear', 'talk', 'include', 'many', 'people', 'hate', 'wonder', 'hate', 'alan', 'sandoval', 'alansandoval', 'december', 'uses', 'word', 'haters', 'new', 'years', 'wish', 'marlene', 'marlene', 'december', 'say', 'happy', 'new', 'year', 'koren', 'pollitt', 'korencarpenter', 'december', 'trump', 'new', 'year', 'eve', 'tweet', 'happy', 'new', 'year', 'including', 'many', 'enemies', 'fought', 'lost', 'badly', 'know', 'love', 'donald', 'j', 'trump', 'realdonaldtrump', 'december', 'nothing', 'new', 'trump', 'years', 'trump', 'directed', 'messages', 'enemies', 'haters', 'new', 'year', 'easter', 'thanksgiving', 'anniversary', 'pic', 'twitter', 'com', 'fpaekypa', 'daniel', 'dale', 'ddale', 'december', 'trump', 'holiday', 'tweets', 'clearly', 'presidential', 'long', 'work', 'hallmark', 'becoming', 'president', 'steven', 'goodine', 'sgoodine', 'december', 'always', 'like', 'difference', 'last', 'years', 'filter', 'breaking', 'roy', 'schulze', 'thbthttt', 'december', 'apart', 'teenager', 'uses', 'term', 'haters', 'wendy', 'wendywhistles', 'december', 'fucking', 'year', 'old', 'knows', 'rainyday', 'december', 'people', 'voted', 'hole', 'thinking', 'would', 'change', 'got', 'power', 'wrong', 'year', 'old', 'men', 'change', 'year', 'older', 'photo', 'andrew', 'burton', 'getty', 'images']), ((1, 0), ['drunk', 'bragging', 'trump', 'staffer', 'started', 'russian', 'collusion', 'investigation', 'house', 'intelligence', 'committee', 'chairman', 'devin', 'nunes', 'going', 'bad', 'day', 'assumption', 'like', 'many', 'us', 'christopher', 'steele', 'dossier', 'prompted', 'russia', 'investigation', 'lashing', 'department', 'justice', 'fbi', 'order', 'protect', 'trump', 'happens', 'dossier', 'started', 'investigation', 'according', 'documents', 'obtained', 'new', 'york', 'times', 'former', 'trump', 'campaign', 'adviser', 'george', 'papadopoulos', 'drunk', 'wine', 'bar', 'revealed', 'knowledge', 'russian', 'opposition', 'research', 'hillary', 'clinton', 'top', 'papadopoulos', 'covfefe', 'boy', 'trump', 'administration', 'alleged', 'much', 'larger', 'role', 'none', 'damning', 'drunken', 'fool', 'wine', 'bar', 'coffee', 'boys', 'help', 'arrange', 'new', 'york', 'meeting', 'trump', 'president', 'abdel', 'fattah', 'el', 'sisi', 'egypt', 'two', 'months', 'election', 'known', 'former', 'aide', 'set', 'meetings', 'world', 'leaders', 'trump', 'team', 'trump', 'ran', 'merely', 'coffee', 'boy', 'may', 'papadopoulos', 'revealed', 'australian', 'diplomat', 'alexander', 'downer', 'russian', 'officials', 'shopping', 'around', 'possible', 'dirt', 'democratic', 'presidential', 'nominee', 'hillary', 'clinton', 'exactly', 'much', 'mr', 'papadopoulos', 'said', 'night', 'kensington', 'wine', 'rooms', 'australian', 'alexander', 'downer', 'unclear', 'report', 'states', 'two', 'months', 'later', 'leaked', 'democratic', 'emails', 'began', 'appearing', 'online', 'australian', 'officials', 'passed', 'information', 'mr', 'papadopoulos', 'american', 'counterparts', 'according', 'four', 'current', 'former', 'american', 'foreign', 'officials', 'direct', 'knowledge', 'australians', 'role', 'papadopoulos', 'pleaded', 'guilty', 'lying', 'f', 'b', 'cooperating', 'witness', 'special', 'counsel', 'robert', 'mueller', 'team', 'presidency', 'badly', 'scripted', 'reality', 'tv', 'show', 'photo', 'win', 'mcnamee', 'getty', 'images']), ((2, 0), ['sheriff', 'david', 'clarke', 'becomes', 'internet', 'joke', 'threatening', 'poke', 'people', 'eye', 'friday', 'revealed', 'former', 'milwaukee', 'sheriff', 'david', 'clarke', 'considered', 'homeland', 'security', 'secretary', 'donald', 'trump', 'administration', 'email', 'scandal', 'january', 'brief', 'run', 'plane', 'clarke', 'fellow', 'passenger', 'dan', 'black', 'later', 'detained', 'police', 'reason', 'whatsoever', 'except', 'maybe', 'feelings', 'hurt', 'clarke', 'messaged', 'police', 'stop', 'black', 'deplaned', 'search', 'warrant', 'executed', 'fbi', 'see', 'exchanges', 'clarke', 'calling', 'fake', 'news', 'even', 'though', 'copies', 'search', 'warrant', 'internet', 'unintimidated', 'lib', 'media', 'attempts', 'smear', 'discredit', 'fake', 'news', 'reports', 'designed', 'silence', 'former', 'sheriff', 'tweeted', 'continue', 'poke', 'eye', 'sharp', 'stick', 'bitch', 'slap', 'scum', 'bags', 'til', 'get', 'attacked', 'better', 'people', 'maga', 'unintimidated', 'lib', 'media', 'attempts', 'smear', 'discredit', 'fake', 'news', 'reports', 'designed', 'silence', 'continue', 'poke', 'eye', 'sharp', 'stick', 'bitch', 'slap', 'scum', 'bags', 'til', 'get', 'attacked', 'better', 'people', 'maga', 'pic', 'twitter', 'com', 'xtzwpdub', 'david', 'clarke', 'jr', 'sheriffclarke', 'december', 'stop', 'breaking', 'news', 'lying', 'lib', 'media', 'makes', 'fake', 'news', 'smear', 'antidote', 'go', 'right', 'punch', 'nose', 'make', 'taste', 'blood', 'nothing', 'gets', 'bully', 'like', 'lying', 'lib', 'media', 'attention', 'better', 'give', 'taste', 'blood', 'neverbackdown', 'pic', 'twitter', 'com', 'tnypshcr', 'david', 'clarke', 'jr', 'sheriffclarke', 'december', 'internet', 'called', 'local', 'newspaper', 'search', 'warrant', 'fake', 'chose', 'file', 'charges', 'time', 'mean', 'especially', 'continue', 'lie', 'months', 'decision', 'charge', 'clarke', 'email', 'search', 'warrant', 'filed', 'https', 'co', 'zcbycwpb', 'keithleblanc', 'keithleblanc', 'december', 'hope', 'rest', 'village', 'people', 'implicated', 'kirk', 'ketchum', 'kirkketchum', 'december', 'slaw', 'baked', 'potatoes', 'french', 'fries', 'pic', 'twitter', 'com', 'fwfxszupxy', 'alt', 'immigration', 'alt_uscis', 'december', 'pic', 'twitter', 'com', 'ymsobljfxu', 'pendulum', 'swinger', 'pendulumswngr', 'december', 'called', 'police', 'friends', 'stand', 'someone', 'made', 'fun', 'hat', 'chris', 'jackson', 'chriscjackson', 'december', 'masterful', 'pshop', 'hat', 'seem', 'never', 'tire', 'think', 'steely', 'resolve', 'one', 'visible', 'eye', 'pic', 'twitter', 'com', 'dwrkzezv', 'chris', 'mohney', 'chrismohney', 'december', 'indicating', 'fingers', 'many', 'people', 'died', 'jail', 'think', 'fingers', 'short', 'dipshit', 'ike', 'barinholtz', 'ikebarinholtz', 'december', 'rofl', 'internet', 'tough', 'guy', 'fake', 'flair', 'pic', 'twitter', 'com', 'ulcfddhkdy', 'kellmecrazy', 'kel_moonface', 'december', 'edgy', 'buddy', 'mrs', 'smh', 'mrssmh', 'december', 'break', 'applebees', 'aaron', 'feltrrr', 'december', 'trying', 'earn', 'still', 'relevant', 'badge', 'circusrebel', 'circusdrew', 'december', 'make', 'sure', 'hydrate', 'drink', 'lots', 'water', 'rumored', 'prisoners', 'denied', 'water', 'prison', 'officials', 'robert', 'klinc', 'robertklinc', 'december', 'terrill', 'thomas', 'year', 'old', 'black', 'man', 'died', 'thirst', 'clarke', 'milwaukee', 'county', 'jail', 'cell', 'april', 'victim', 'homicide', 'thought', 'point', 'repeated', 'enough', 'photo', 'spencer', 'platt', 'getty', 'images']), ((3, 0), ['trump', 'obsessed', 'even', 'obama', 'name', 'coded', 'website', 'images', 'christmas', 'day', 'donald', 'trump', 'announced', 'would', 'back', 'work', 'following', 'day', 'golfing', 'fourth', 'day', 'row', 'former', 'reality', 'show', 'star', 'blasted', 'former', 'president', 'barack', 'obama', 'playing', 'golf', 'trump', 'track', 'outpace', 'number', 'golf', 'games', 'predecessor', 'played', 'updated', 'tracker', 'trump', 'appearances', 'trump', 'properties', 'rounds', 'golf', 'including', 'today', 'pace', 'pass', 'obama', 'first', 'term', 'total', 'july', 'next', 'year', 'https', 'co', 'fgvacxrtj', 'pic', 'twitter', 'com', 'gemcjqtbh', 'philip', 'bump', 'pbump', 'december', 'makes', 'washington', 'post', 'reporter', 'discovered', 'trump', 'website', 'really', 'weird', 'everything', 'administration', 'bizarre', 'af', 'coding', 'contained', 'reference', 'obama', 'golf', 'unlike', 'obama', 'working', 'fix', 'problem', 'golf', 'course', 'however', 'coding', 'done', 'correctly', 'website', 'donald', 'trump', 'spent', 'several', 'days', 'row', 'golf', 'course', 'coded', 'serve', 'following', 'message', 'event', 'internal', 'server', 'error', 'https', 'co', 'zrwpymxrcz', 'pic', 'twitter', 'com', 'wiqsqnnzw', 'christopher', 'ingraham', '_cingraham', 'december', 'snippet', 'code', 'appears', 'https', 'co', 'dkhwalhb', 'pages', 'footer', 'says', 'paid', 'rnc', 'pic', 'twitter', 'com', 'oazdtb', 'christopher', 'ingraham', '_cingraham', 'december', 'also', 'https', 'co', 'ayblgmkz', 'others', 'noted', 'thread', 'weird', 'code', 'clear', 'would', 'ever', 'actually', 'display', 'knows', 'christopher', 'ingraham', '_cingraham', 'december', 'coding', 'called', 'reference', 'obama', 'deleted', 'update', 'golf', 'error', 'message', 'removed', 'trump', 'gop', 'websites', 'also', 'fixed', 'javascript', 'vs', 'problem', 'still', 'clear', 'messages', 'would', 'actually', 'display', 'since', 'actual', 'presumably', 'page', 'displays', 'different', 'message', 'pic', 'twitter', 'com', 'zdmyqsmy', 'christopher', 'ingraham', '_cingraham', 'december', 'suggests', 'someone', 'either', 'rnc', 'trump', 'admin', 'sensitive', 'enough', 'trump', 'golf', 'problem', 'make', 'issue', 'go', 'away', 'quickly', 'people', 'noticed', 'idea', 'much', 'love', 'see', 'email', 'exchange', 'led', 'us', 'christopher', 'ingraham', '_cingraham', 'december', 'code', 'f', 'cked', 'best', 'part', 'using', 'assignment', 'operator', 'means', 'bit', 'code', 'never', 'get', 'run', 'look', 'lines', 'errorcode', 'always', 'twtrsux', 'december', 'trump', 'coders', 'code', 'nobody', 'surprised', 'tim', 'peterson', 'timrpeterson', 'december', 'donald', 'trump', 'obsessed', 'obama', 'name', 'even', 'coding', 'website', 'played', 'golf', 'photo', 'joe', 'raedle', 'getty', 'images']), ((4, 0), ['pope', 'francis', 'called', 'donald', 'trump', 'christmas', 'speech', 'pope', 'francis', 'used', 'annual', 'christmas', 'day', 'message', 'rebuke', 'donald', 'trump', 'without', 'even', 'mentioning', 'name', 'pope', 'delivered', 'message', 'days', 'members', 'united', 'nations', 'condemned', 'trump', 'move', 'recognize', 'jerusalem', 'capital', 'israel', 'pontiff', 'prayed', 'monday', 'peaceful', 'coexistence', 'two', 'states', 'within', 'mutually', 'agreed', 'internationally', 'recognized', 'borders', 'see', 'jesus', 'children', 'middle', 'east', 'continue', 'suffer', 'growing', 'tensions', 'israelis', 'palestinians', 'francis', 'said', 'festive', 'day', 'let', 'us', 'ask', 'lord', 'peace', 'jerusalem', 'holy', 'land', 'let', 'us', 'pray', 'resume', 'dialogue', 'may', 'prevail', 'parties', 'negotiated', 'solution', 'finally', 'reached', 'pope', 'went', 'plead', 'acceptance', 'refugees', 'forced', 'homes', 'issue', 'trump', 'continues', 'fight', 'francis', 'used', 'jesus', 'place', 'inn', 'analogy', 'today', 'winds', 'war', 'blowing', 'world', 'outdated', 'model', 'development', 'continues', 'produce', 'human', 'societal', 'environmental', 'decline', 'christmas', 'invites', 'us', 'focus', 'sign', 'child', 'recognize', 'faces', 'little', 'children', 'especially', 'like', 'jesus', 'place', 'inn', 'said', 'jesus', 'knows', 'well', 'pain', 'welcomed', 'hard', 'place', 'lay', 'one', 'head', 'added', 'may', 'hearts', 'closed', 'homes', 'bethlehem', 'pope', 'said', 'mary', 'joseph', 'immigrants', 'struggled', 'find', 'safe', 'place', 'stay', 'bethlehem', 'leave', 'people', 'home', 'land', 'francis', 'said', 'comfortable', 'easy', 'journey', 'young', 'couple', 'child', 'heart', 'full', 'hope', 'expectation', 'child', 'born', 'yet', 'steps', 'weighed', 'uncertainties', 'dangers', 'attend', 'leave', 'home', 'behind', 'many', 'footsteps', 'hidden', 'footsteps', 'joseph', 'mary', 'francis', 'said', 'sunday', 'see', 'tracks', 'entire', 'families', 'forced', 'set', 'day', 'see', 'tracks', 'millions', 'persons', 'choose', 'go', 'away', 'driven', 'land', 'leave', 'behind', 'dear', 'ones', 'amen', 'photo', 'christopher', 'furlong', 'getty', 'images'])]\n","time: 2.04 s (started: 2022-03-20 11:32:27 +00:00)\n"]}],"source":["# remove stopwords\n","def remove_stopwords(words, lang='english'):\n","  from nltk.corpus import stopwords\n","  lang_stopwords = stopwords.words(lang)\n","  stopwords_removed = [w for w in words if w not in lang_stopwords]\n","  return stopwords_removed\n","\n","label_data_no_stopwords = label_data_words.map(lambda f: (f[0], remove_stopwords(f[1])))\n","main_data_no_stopwords = main_data_words.map(lambda f: (f[0], remove_stopwords(f[1])))\n","print(label_data_no_stopwords.take(5))\n","\n","# lemmatization\n","# Function to find part of speech tag for a word\n","def find_pos(word):\n","    # Part of Speech constants\n","    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n","\n","    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n","    \n","    # Adjective tags - 'JJ', 'JJR', 'JJS'\n","    if pos.lower()[0] == 'j':\n","        return 'a'\n","    # Adverb tags - 'RB', 'RBR', 'RBS'\n","    elif pos.lower()[0] == 'r':\n","        return 'r'\n","    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n","    elif pos.lower()[0] == 'v':\n","        return 'v'\n","\n","    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n","    else:\n","        return 'n'\n","\n","\n","# Function to apply lemmatization to a list of words\n","def words_lemmatizer(words, encoding=\"utf8\"):\n","    lemma_words = []\n","    wl = WordNetLemmatizer()\n","    for word in words:\n","        pos = find_pos(word)\n","        lemma_words.append(wl.lemmatize(word, pos))\n","    return lemma_words\n","    \n","\n","label_data_lemmatization = label_data_no_stopwords.map(lambda f: (f[0][0], f[0][1], words_lemmatizer(f[1])))\n","main_data_lemmatization = main_data_no_stopwords.map(lambda f: (f[0], words_lemmatizer(f[1])))\n","# print(label_data_lemmatization.take(5))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28592,"status":"ok","timestamp":1647775978914,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"lclM5MfFAxX0","outputId":"ec017a26-a734-470e-e98c-98d8af0db3b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+--------------------+\n","| id|label|               token|\n","+---+-----+--------------------+\n","|  0|    0|[donald, trump, s...|\n","|  1|    0|[drunk, bragging,...|\n","|  2|    0|[sheriff, david, ...|\n","|  3|    0|[trump, obsess, e...|\n","|  4|    0|[pope, francis, c...|\n","|  5|    0|[racist, alabama,...|\n","|  6|    0|[fresh, golf, cou...|\n","|  7|    0|[trump, say, insa...|\n","|  8|    0|[former, cia, dir...|\n","|  9|    0|[watch, brand, ne...|\n","| 10|    0|[papa, john, foun...|\n","| 11|    0|[watch, paul, rya...|\n","| 12|    0|[bad, news, trump...|\n","| 13|    0|[watch, lindsey, ...|\n","| 14|    0|[heiress, disney,...|\n","| 15|    0|[tone, deaf, trum...|\n","| 16|    0|[internet, brutal...|\n","| 17|    0|[mueller, spokesm...|\n","| 18|    0|[snl, hilariously...|\n","| 19|    0|[republican, sena...|\n","+---+-----+--------------------+\n","only showing top 20 rows\n","\n","+--------------------+--------------------+\n","|                  id|               token|\n","+--------------------+--------------------+\n","|6a175f46bcd24d39b...|[muslim, bust, st...|\n","|2bdc29d12605ef9cf...|[attorney, genera...|\n","|c70e149fdd53de5e6...|[break, weiner, c...|\n","|7cf7c15731ac2a116...|[pin, drop, speec...|\n","|0206b54719c7e241f...|[fantastic, trump...|\n","|8f30f5ea14c9d5914...|[hillary, go, abs...|\n","|d3cc0fe38f41a59f7...|[break, nypd, rea...|\n","|b4bbf8b5c19e8864f...|[wow, whistleblow...|\n","|a19aabaa5a61eb8bc...|[break, clinton, ...|\n","|f54d8e13010d0a798...|[evil, hillary, s...|\n","|4d3faf17519cfa46c...|[yikes, hillary, ...|\n","|7f90d71cc69893f4c...|[say, goodbye, ho...|\n","|fd2c048d7e03f7260...|[kid, college, gi...|\n","|c8d4c0a88af223f1b...|[boom, math, show...|\n","|f0b221ac2a32d3f53...|[boom, president,...|\n","|a9efba05a81e5b106...|[trump, supporter...|\n","|13e3e1983787c7687...|[tomi, lahren, sp...|\n","|162b39e6518af4e59...|[boycottcomedian,...|\n","|59899b8db5916d23b...|[never, sell, ori...|\n","|1fe4c0fa4ba9e410f...|[sorry, liberal, ...|\n","+--------------------+--------------------+\n","only showing top 20 rows\n","\n","time: 28.5 s (started: 2022-03-20 11:32:29 +00:00)\n"]}],"source":["# generate spark df of labeled dataset\n","label_data_df = spark.createDataFrame(label_data_lemmatization, ['id', 'label', 'token'])\n","label_data_df.show()\n","\n","# generate spark df of unlabeled dataset\n","main_data_df = spark.createDataFrame(main_data_lemmatization, ['id', 'token'])\n","main_data_df.show()"]},{"cell_type":"markdown","metadata":{"id":"lU-4Fz06fbYO"},"source":["## CountVector\n","- train the count vector model (no need to run again)\n","- save the model (no need to run again)\n","- read the pre-trained model and generate the count vectors for the datasets\n","\n","### Output: \n","- label_data_cv (spark dataframe, column=['id', 'label', 'token', 'count_vector'])\n","- main_data_cv (spark dataframe, column=['id', 'token', 'count_vector'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1647775978914,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"VsA2ykDyBo9N","outputId":"662f38c9-c773-45b9-a2e7-b4021da11141"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 1.46 ms (started: 2022-03-20 11:32:57 +00:00)\n"]}],"source":["# # generate the count vector for the labeled dataset\n","# cv = CountVectorizer(inputCol='token', outputCol='count_vector')\n","# m_cv = cv.fit(label_data_df)\n","# label_data_cv = m_cv.transform(label_data_df)\n","# label_data_cv.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647775978914,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"x-SnTMo-Ph-u","outputId":"ad44192e-c89f-4c1f-adef-88c3bfeb4e23"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 1.1 ms (started: 2022-03-20 11:32:57 +00:00)\n"]}],"source":["# # generate the count vector for the unlabeled dataset\n","# main_data_cv = m_cv.transform(main_data_df)\n","# main_data_cv.show(8, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24460,"status":"ok","timestamp":1647776003371,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"7eZU27k8S8iX","outputId":"3ca56e27-5f64-42e2-da78-5283cd020c9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+--------------------+--------------------+\n","| id|label|               token|        count_vector|\n","+---+-----+--------------------+--------------------+\n","|  0|    0|[donald, trump, s...|(100949,[0,1,3,5,...|\n","|  1|    0|[drunk, bragging,...|(100949,[0,1,2,3,...|\n","|  2|    0|[sheriff, david, ...|(100949,[0,6,7,8,...|\n","|  3|    0|[trump, obsess, e...|(100949,[0,1,2,3,...|\n","|  4|    0|[pope, francis, c...|(100949,[0,1,2,4,...|\n","|  5|    0|[racist, alabama,...|(100949,[1,5,6,14...|\n","|  6|    0|[fresh, golf, cou...|(100949,[0,1,3,7,...|\n","|  7|    0|[trump, say, insa...|(100949,[0,1,3,4,...|\n","|  8|    0|[former, cia, dir...|(100949,[0,2,3,4,...|\n","|  9|    0|[watch, brand, ne...|(100949,[0,1,2,3,...|\n","| 10|    0|[papa, john, foun...|(100949,[0,2,5,6,...|\n","| 11|    0|[watch, paul, rya...|(100949,[0,1,2,4,...|\n","| 12|    0|[bad, news, trump...|(100949,[0,1,2,3,...|\n","| 13|    0|[watch, lindsey, ...|(100949,[0,1,3,9,...|\n","| 14|    0|[heiress, disney,...|(100949,[0,1,2,6,...|\n","| 15|    0|[tone, deaf, trum...|(100949,[0,1,5,7,...|\n","| 16|    0|[internet, brutal...|(100949,[0,3,4,6,...|\n","| 17|    0|[mueller, spokesm...|(100949,[0,1,3,7,...|\n","| 18|    0|[snl, hilariously...|(100949,[0,1,3,4,...|\n","| 19|    0|[republican, sena...|(100949,[0,1,3,5,...|\n","+---+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n","+--------------------+--------------------+--------------------+\n","|                  id|               token|        count_vector|\n","+--------------------+--------------------+--------------------+\n","|6a175f46bcd24d39b...|[muslim, bust, st...|(100949,[8,9,10,1...|\n","|2bdc29d12605ef9cf...|[attorney, genera...|(100949,[4,10,12,...|\n","|c70e149fdd53de5e6...|[break, weiner, c...|(100949,[1,2,4,5,...|\n","|7cf7c15731ac2a116...|[pin, drop, speec...|(100949,[0,3,17,3...|\n","|0206b54719c7e241f...|[fantastic, trump...|(100949,[0,3,4,6,...|\n","|8f30f5ea14c9d5914...|[hillary, go, abs...|(100949,[0,1,6,9,...|\n","|d3cc0fe38f41a59f7...|[break, nypd, rea...|(100949,[1,3,4,6,...|\n","|b4bbf8b5c19e8864f...|[wow, whistleblow...|(100949,[0,1,4,7,...|\n","|a19aabaa5a61eb8bc...|[break, clinton, ...|(100949,[1,4,5,13...|\n","|f54d8e13010d0a798...|[evil, hillary, s...|(100949,[0,1,3,6,...|\n","|4d3faf17519cfa46c...|[yikes, hillary, ...|(100949,[9,19,25,...|\n","|7f90d71cc69893f4c...|[say, goodbye, ho...|(100949,[0,1,2,3,...|\n","|fd2c048d7e03f7260...|[kid, college, gi...|(100949,[0,2,3,6,...|\n","|c8d4c0a88af223f1b...|[boom, math, show...|(100949,[0,2,4,5,...|\n","|f0b221ac2a32d3f53...|[boom, president,...|(100949,[3,19,24,...|\n","|a9efba05a81e5b106...|[trump, supporter...|(100949,[0,8,9,14...|\n","|13e3e1983787c7687...|[tomi, lahren, sp...|(100949,[0,1,19,2...|\n","|162b39e6518af4e59...|[boycottcomedian,...|(100949,[0,1,2,4,...|\n","|59899b8db5916d23b...|[never, sell, ori...|(100949,[0,1,2,3,...|\n","|1fe4c0fa4ba9e410f...|[sorry, liberal, ...|(100949,[0,1,2,4,...|\n","+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n","time: 24.3 s (started: 2022-03-20 11:32:57 +00:00)\n"]}],"source":["# save the trained countvectorizer model\n","modelPath = '/Users/yishun/Desktop/BAModule/CS5344/group project/Data Processing/count_vectorizer_model'\n","# m_cv.save(modelPath)\n","\n","# generate the count vectors directly using the pre-trained model\n","loadedModel = CountVectorizerModel.load(modelPath)\n","label_data_cv = loadedModel.transform(label_data_df)\n","main_data_cv = loadedModel.transform(main_data_df)\n","\n","label_data_cv.show()\n","main_data_cv.show()"]},{"cell_type":"markdown","metadata":{"id":"06FXMiiLf-vf"},"source":["## TF-IDF Vector\n","### Steps:\n","- use HashingTF to calculate the TF\n","- train the TF-IDF vector model (no need to run again)\n","- save the model (no need to run again)\n","- read the pre-trained model and generate the TF-IDF vectors for the datasets\n","\n","### Output: \n","- label_data_tf_idf (spark dataframe, column=['id', 'label', 'token', 'tf_vector', 'tf_idf_vector'])\n","- main_data_tf_idf (spark dataframe, column=['id', 'token', 'tf_vector', 'tf_idf_vector'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6895,"status":"ok","timestamp":1647776010255,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"FHAJ8FLGA0iE","outputId":"affda7f8-40eb-47a5-ee69-9d140f3c71ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+--------------------+--------------------+\n","| id|label|               token|           tf_vector|\n","+---+-----+--------------------+--------------------+\n","|  0|    0|[donald, trump, s...|(262144,[531,1512...|\n","|  1|    0|[drunk, bragging,...|(262144,[3148,471...|\n","|  2|    0|[sheriff, david, ...|(262144,[531,794,...|\n","|  3|    0|[trump, obsess, e...|(262144,[531,654,...|\n","|  4|    0|[pope, francis, c...|(262144,[2437,392...|\n","|  5|    0|[racist, alabama,...|(262144,[1226,425...|\n","|  6|    0|[fresh, golf, cou...|(262144,[1004,151...|\n","|  7|    0|[trump, say, insa...|(262144,[2306,594...|\n","|  8|    0|[former, cia, dir...|(262144,[619,1004...|\n","|  9|    0|[watch, brand, ne...|(262144,[4214,853...|\n","| 10|    0|[papa, john, foun...|(262144,[2325,236...|\n","| 11|    0|[watch, paul, rya...|(262144,[531,1512...|\n","| 12|    0|[bad, news, trump...|(262144,[1451,160...|\n","| 13|    0|[watch, lindsey, ...|(262144,[531,1512...|\n","| 14|    0|[heiress, disney,...|(262144,[531,1512...|\n","| 15|    0|[tone, deaf, trum...|(262144,[1512,410...|\n","| 16|    0|[internet, brutal...|(262144,[531,1512...|\n","| 17|    0|[mueller, spokesm...|(262144,[8538,880...|\n","| 18|    0|[snl, hilariously...|(262144,[619,3048...|\n","| 19|    0|[republican, sena...|(262144,[108,531,...|\n","+---+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n","time: 7.01 s (started: 2022-03-20 11:33:21 +00:00)\n"]}],"source":["# generate the TF-IDF vector of the labeled dataset \n","tf = HashingTF(inputCol='token', outputCol='tf_vector')\n","label_data_tf = tf.transform(label_data_df)\n","label_data_tf.show()\n","\n","# tf_idf = IDF(inputCol='tf_vector', outputCol='tf_idf_vector')\n","# m_tf_idf = tf_idf.fit(label_data_tf)\n","# label_data_tf_idf = m_tf_idf.transform(label_data_tf)\n","# label_data_tf_idf.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1647776010256,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"5tZfXHlAPqxv","outputId":"bf615d3a-b832-4a3b-91e2-ae85a1b519c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 39.4 ms (started: 2022-03-20 11:33:28 +00:00)\n"]}],"source":["# generate the TF-IDF vector of the unlabeled dataset\n","main_data_tf = tf.transform(main_data_df)\n","# main_data_tf_idf = m_tf_idf.transform(main_data_tf)\n","# main_data_tf_idf.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16934,"status":"ok","timestamp":1647776027185,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"cu81ygU0TQmt","outputId":"787eea83-edf8-447c-ab78-264bebf78642"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+--------------------+--------------------+--------------------+\n","| id|label|               token|           tf_vector|       tf_idf_vector|\n","+---+-----+--------------------+--------------------+--------------------+\n","|  0|    0|[donald, trump, s...|(262144,[531,1512...|(262144,[531,1512...|\n","|  1|    0|[drunk, bragging,...|(262144,[3148,471...|(262144,[3148,471...|\n","|  2|    0|[sheriff, david, ...|(262144,[531,794,...|(262144,[531,794,...|\n","|  3|    0|[trump, obsess, e...|(262144,[531,654,...|(262144,[531,654,...|\n","|  4|    0|[pope, francis, c...|(262144,[2437,392...|(262144,[2437,392...|\n","|  5|    0|[racist, alabama,...|(262144,[1226,425...|(262144,[1226,425...|\n","|  6|    0|[fresh, golf, cou...|(262144,[1004,151...|(262144,[1004,151...|\n","|  7|    0|[trump, say, insa...|(262144,[2306,594...|(262144,[2306,594...|\n","|  8|    0|[former, cia, dir...|(262144,[619,1004...|(262144,[619,1004...|\n","|  9|    0|[watch, brand, ne...|(262144,[4214,853...|(262144,[4214,853...|\n","| 10|    0|[papa, john, foun...|(262144,[2325,236...|(262144,[2325,236...|\n","| 11|    0|[watch, paul, rya...|(262144,[531,1512...|(262144,[531,1512...|\n","| 12|    0|[bad, news, trump...|(262144,[1451,160...|(262144,[1451,160...|\n","| 13|    0|[watch, lindsey, ...|(262144,[531,1512...|(262144,[531,1512...|\n","| 14|    0|[heiress, disney,...|(262144,[531,1512...|(262144,[531,1512...|\n","| 15|    0|[tone, deaf, trum...|(262144,[1512,410...|(262144,[1512,410...|\n","| 16|    0|[internet, brutal...|(262144,[531,1512...|(262144,[531,1512...|\n","| 17|    0|[mueller, spokesm...|(262144,[8538,880...|(262144,[8538,880...|\n","| 18|    0|[snl, hilariously...|(262144,[619,3048...|(262144,[619,3048...|\n","| 19|    0|[republican, sena...|(262144,[108,531,...|(262144,[108,531,...|\n","+---+-----+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n","+--------------------+--------------------+--------------------+--------------------+\n","|                  id|               token|           tf_vector|       tf_idf_vector|\n","+--------------------+--------------------+--------------------+--------------------+\n","|6a175f46bcd24d39b...|[muslim, bust, st...|(262144,[3928,659...|(262144,[3928,659...|\n","|2bdc29d12605ef9cf...|[attorney, genera...|(262144,[1152,777...|(262144,[1152,777...|\n","|c70e149fdd53de5e6...|[break, weiner, c...|(262144,[2437,274...|(262144,[2437,274...|\n","|7cf7c15731ac2a116...|[pin, drop, speec...|(262144,[4092,101...|(262144,[4092,101...|\n","|0206b54719c7e241f...|[fantastic, trump...|(262144,[1451,432...|(262144,[1451,432...|\n","|8f30f5ea14c9d5914...|[hillary, go, abs...|(262144,[403,531,...|(262144,[403,531,...|\n","|d3cc0fe38f41a59f7...|[break, nypd, rea...|(262144,[1365,274...|(262144,[1365,274...|\n","|b4bbf8b5c19e8864f...|[wow, whistleblow...|(262144,[4562,463...|(262144,[4562,463...|\n","|a19aabaa5a61eb8bc...|[break, clinton, ...|(262144,[4210,538...|(262144,[4210,538...|\n","|f54d8e13010d0a798...|[evil, hillary, s...|(262144,[8538,920...|(262144,[8538,920...|\n","|4d3faf17519cfa46c...|[yikes, hillary, ...|(262144,[33727,14...|(262144,[33727,14...|\n","|7f90d71cc69893f4c...|[say, goodbye, ho...|(262144,[1303,228...|(262144,[1303,228...|\n","|fd2c048d7e03f7260...|[kid, college, gi...|(262144,[303,378,...|(262144,[303,378,...|\n","|c8d4c0a88af223f1b...|[boom, math, show...|(262144,[2437,388...|(262144,[2437,388...|\n","|f0b221ac2a32d3f53...|[boom, president,...|(262144,[5471,866...|(262144,[5471,866...|\n","|a9efba05a81e5b106...|[trump, supporter...|(262144,[531,1512...|(262144,[531,1512...|\n","|13e3e1983787c7687...|[tomi, lahren, sp...|(262144,[8664,145...|(262144,[8664,145...|\n","|162b39e6518af4e59...|[boycottcomedian,...|(262144,[2306,274...|(262144,[2306,274...|\n","|59899b8db5916d23b...|[never, sell, ori...|(262144,[4714,538...|(262144,[4714,538...|\n","|1fe4c0fa4ba9e410f...|[sorry, liberal, ...|(262144,[956,991,...|(262144,[956,991,...|\n","+--------------------+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n","time: 16.9 s (started: 2022-03-20 11:33:29 +00:00)\n"]}],"source":["# save the trained IDF Model \n","modelPath = '/Users/yishun/Desktop/BAModule/CS5344/group project/Data Processing/TF_IDF_model'\n","# m_tf_idf.save(modelPath)\n","\n","# generate the TF-IDF vectors directly using the pre-trained model\n","loadedModel = IDFModel.load(modelPath)\n","label_data_tf_idf = loadedModel.transform(label_data_tf)\n","main_data_tf_idf = loadedModel.transform(main_data_tf)\n","\n","label_data_tf_idf.show()\n","main_data_tf_idf.show()"]},{"cell_type":"markdown","metadata":{"id":"mvdOe4TgiwT6"},"source":["## Standard the Format of the Outputs\n","### Outputs: \n","- BoW 1-gram of the labeled dataset: label_cv_output (spark dataframe, column=['id', 'features', 'label']) \n","- BoW 1-gram of the unlabeled dataset: main_cv_output (spark dataframe, column=['id', 'features'])\n","- TF-IDF of the labeled dataset: label_tfidf_output (spark dataframe, column=['id', 'features', 'label'])\n","- TF-IDF of the unlabeled dataset: main_tfidf_output (spark dataframe, column=['id', 'features'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6849,"status":"ok","timestamp":1647776119846,"user":{"displayName":"Zhong Vanessa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16415500996503320513"},"user_tz":-480},"id":"T6Gl3rA5i42S","outputId":"7d800fcc-1684-4898-b4ff-8b8e565cc2ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+--------------------+-----+\n","| id|            features|label|\n","+---+--------------------+-----+\n","|  0|(100949,[0,1,3,5,...|    0|\n","|  1|(100949,[0,1,2,3,...|    0|\n","|  2|(100949,[0,6,7,8,...|    0|\n","|  3|(100949,[0,1,2,3,...|    0|\n","|  4|(100949,[0,1,2,4,...|    0|\n","|  5|(100949,[1,5,6,14...|    0|\n","|  6|(100949,[0,1,3,7,...|    0|\n","|  7|(100949,[0,1,3,4,...|    0|\n","|  8|(100949,[0,2,3,4,...|    0|\n","|  9|(100949,[0,1,2,3,...|    0|\n","| 10|(100949,[0,2,5,6,...|    0|\n","| 11|(100949,[0,1,2,4,...|    0|\n","| 12|(100949,[0,1,2,3,...|    0|\n","| 13|(100949,[0,1,3,9,...|    0|\n","| 14|(100949,[0,1,2,6,...|    0|\n","| 15|(100949,[0,1,5,7,...|    0|\n","| 16|(100949,[0,3,4,6,...|    0|\n","| 17|(100949,[0,1,3,7,...|    0|\n","| 18|(100949,[0,1,3,4,...|    0|\n","| 19|(100949,[0,1,3,5,...|    0|\n","+---+--------------------+-----+\n","only showing top 20 rows\n","\n","time: 6.06 s (started: 2022-03-20 11:35:12 +00:00)\n"]}],"source":["# Output\n","label_cv_output = label_data_cv.select('id', 'count_vector', 'label')\n","main_cv_output = main_data_cv.select('id', 'count_vector')\n","label_tfidf_output = label_data_tf_idf.select('id', 'tf_idf_vector', 'label')\n","main_tfidf_output = main_data_tf_idf.select('id', 'tf_idf_vector')\n","\n","label_cv_output = label_cv_output.withColumnRenamed('count_vector', 'features')\n","main_cv_output = main_cv_output.withColumnRenamed('count_vector', 'features')\n","label_tfidf_output = label_tfidf_output.withColumnRenamed('tf_idf_vector', 'features')\n","main_tfidf_output = main_tfidf_output.withColumnRenamed('tf_idf_vector', 'features')\n","\n","label_cv_output.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pyspark.ml.feature as ft\n","import numpy as np \n","import pandas as pd\n","\n","import pandas as pd\n","from pyspark.sql import SparkSession\n","import pyspark.ml.tuning as tune\n","\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.classification import LogisticRegression,RandomForestClassifier,DecisionTreeClassifier,GBTClassifier\n","\n","\n","\n","# spark = SparkSession \\\n","#     .builder \\\n","#     .appName('my_first_app_name') \\\n","#     .getOrCreate()\n","\n","#Data Example, for testing the code\n","# columns=['ID','word1','word2','label']\n","# number = np.array([[1,1,0,1],[2,0,1,0],[3,0,1,0],[4,1,1,1],[1,1,0,1],[2,0,1,0],[3,0,1,0],[4,1,1,1],[1,1,0,1],[2,0,1,0],[3,0,1,0],[4,1,1,1],[1,1,0,1],[2,0,1,0],[3,0,1,0],[4,1,1,1]])\n","# pd_data = pd.DataFrame(number,columns=columns)\n","# spark_data=spark.createDataFrame(pd_data)\n","# spark_data.show()\n","\n","# data = pd.read_csv('/Users/yishun/Desktop/BAModule/BT5126 Hands on with BA/5126gp/Final_Data.csv')\n","# data = data.rename(columns={'result':'label'})\n","# spark_data=spark.createDataFrame(data)\n","def Model_part(spark_data):\n","    '''Input: Spark Dataframe, Output: two list, first list contains 4 best model, second list are the validation AUC-score\n","    '''\n","\n","    # 80% training set 20% test set\n","    train_set, test_set = spark_data.randomSplit([0.8,0.2],seed=42)\n","\n","    # The input dataset\n","    transform_train_set = train_set.select('features','label')\n","    transform_test_set = test_set.select('features','label')\n","\n","    # Initialize 4 models\n","    logistic = LogisticRegression(featuresCol='features',labelCol='label')\n","    decision_tree = DecisionTreeClassifier(featuresCol='features',labelCol='label')\n","    random_forest = RandomForestClassifier(featuresCol='features',labelCol='label')\n","    gbt = GBTClassifier(featuresCol='features',labelCol='label')\n","\n","    # Set the parameter grids for them\n","    loggrid = tune.ParamGridBuilder()\\\n","        .addGrid(logistic.maxIter, [5,10,50])\\\n","        .addGrid(logistic.regParam, [0.1,0.01,0.05]) \\\n","        .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0])\\\n","        .build()\n","\n","    dtcgrid = tune.ParamGridBuilder()\\\n","        .addGrid(decision_tree.maxDepth, [3,6,7,9])\\\n","        .build()\n","\n","    rfgrid = tune.ParamGridBuilder() \\\n","        .addGrid(random_forest.numTrees,[100,200,300]) \\\n","        .addGrid(random_forest.maxDepth, [2,3,4,5]) \\\n","        .build()\n","\n","    gbtgrid = tune.ParamGridBuilder() \\\n","        .addGrid(gbt.maxDepth,[2,3,4]) \\\n","        .addGrid(gbt.stepSize,[0.01,0.001,0.005]) \\\n","        .build()\n","\n","    # 5-fold Cross validation\n","    logcv = tune.CrossValidator(\n","        estimator=logistic,\n","        estimatorParamMaps=loggrid,\n","        evaluator=BinaryClassificationEvaluator(),\n","        numFolds=5\n","    )\n","    dtcv = tune.CrossValidator(\n","        estimator=decision_tree,\n","        estimatorParamMaps=dtcgrid,\n","        evaluator=BinaryClassificationEvaluator(),\n","        numFolds=5\n","    )\n","    rfcv = tune.CrossValidator(\n","        estimator=random_forest,\n","        estimatorParamMaps=rfgrid,\n","        evaluator=BinaryClassificationEvaluator(),\n","        numFolds=5\n","    )\n","    gbtcv = tune.CrossValidator(\n","        estimator=gbt,\n","        estimatorParamMaps=gbtgrid,\n","        evaluator=BinaryClassificationEvaluator(),\n","        numFolds=5\n","    )\n","\n","    # Fit on the training set\n","    logmodel = logcv.fit(transform_train_set)\n","    dtmodel = dtcv.fit(transform_train_set)\n","    rfmodel = rfcv.fit(transform_train_set)\n","    gbtmodel = gbtcv.fit(transform_train_set)\n","\n","    # Default ROC-AUC\n","    evaluator = BinaryClassificationEvaluator(rawPredictionCol= 'probability',labelCol='label')\n","    # Return all the best model\n","    best_model_list = [logmodel.bestModel,dtmodel.bestModel,rfmodel.bestModel,gbtmodel.bestModel]\n","    # Return\n","    auc_list = [evaluator.evaluate(model.transform(transform_test_set)) for model in best_model_list]\n","\n","    return best_model_list,auc_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv_model, cv_auc = Model_part(label_cv_output)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tfidf_model, ifidf_auc = Model_part(label_tfidf_output)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOzHV8S4DH8xlOL/7jPxqMZ","collapsed_sections":[],"machine_shape":"hm","name":"Data Preprocessing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
